name: Build & Deploy Pages (fable-collector)

on:
  workflow_dispatch:
    inputs:
      tz:
        description: "IANA timezone pour le filtre local (ex: Africa/Tunis)"
        default: "Africa/Tunis"
      local_hours_csv:
        description: "Heures locales autorisées (HH séparées par des virgules)"
        default: "00,06,12,18"
      force:
        description: "Ignorer le filtre d'heure locale et exécuter maintenant"
        type: boolean
        default: false
      window_hours:
        description: "Horizon de prévision en heures"
        default: "48"
      start_iso:
        description: "Optionnel: début ISO (YYYY-MM-DDTHH:MM)"
        required: false
      only_sites:
        description: "Optionnel: restreindre à certains sites (CSV)"
        required: false
      reader_home:
        description: "JSON du port d’attache pour le reader"
        default: "gammarth-port.json"

  schedule:
    # 00:00/06:00/12:00/18:00 Africa/Tunis (UTC+1) + garde-fou horaire
    - cron: "0 * * * *"

  push:
    paths:
      - ".github/workflows/pages.yml"
      - "requirements.txt"
      - "main.py"
      - "reader.py"
      - "sites.yaml"
      - "rules.yaml"
      - "stats/index.html"    # ← pour relancer le workflow si tu modifies le fichier statique
      - "Public/index.html"    # ← déclenche aussi sur la vraie page publique
permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      should_run: ${{ steps.gate.outputs.should_run }}
      reason: ${{ steps.gate.outputs.reason }}
      tz_effective: ${{ steps.gate.outputs.tz_effective }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # --- Gate heure locale / TZ ---
      - name: Gate on local hour (or force)
        id: gate
        env:
          DEFAULT_TZ: "Africa/Tunis"
          DEFAULT_LOCAL_HOURS: "00,06,12,18"
          INPUT_TZ: ${{ github.event_name == 'workflow_dispatch' && inputs.tz || '' }}
          INPUT_HOURS: ${{ github.event_name == 'workflow_dispatch' && inputs.local_hours_csv || '' }}
          INPUT_FORCE: ${{ github.event_name == 'workflow_dispatch' && (inputs.force && 'true' || 'false') || 'false' }}
        run: |
          TZ_INPUT="${INPUT_TZ:-$DEFAULT_TZ}"
          HOURS_CSV="${INPUT_HOURS:-$DEFAULT_LOCAL_HOURS}"
          FORCE="${INPUT_FORCE}"
          # Si l'événement est un push, on force un run immédiat
          [ "${{ github.event_name }}" = "push" ] && FORCE="true"

          if [ "$FORCE" = "true" ]; then
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "reason=forced" >> $GITHUB_OUTPUT
          else
            hour=$(TZ=$TZ_INPUT date +%H)
            if echo "$HOURS_CSV" | tr ',' '\n' | grep -qx "$hour"; then
              echo "should_run=true" >> $GITHUB_OUTPUT
              echo "reason=matched_local_hour_$hour" >> $GITHUB_OUTPUT
            else
              echo "should_run=false" >> $GITHUB_OUTPUT
              echo "reason=skipped_local_hour_$hour" >> $GITHUB_OUTPUT
            fi
          fi
          echo "tz_effective=$TZ_INPUT" >> $GITHUB_OUTPUT

      - name: Show gate decision
        run: |
          echo "Gate: ${{ steps.gate.outputs.should_run }} (${{ steps.gate.outputs.reason }}) TZ=${{ steps.gate.outputs.tz_effective }}"

      - name: Setup Python
        if: steps.gate.outputs.should_run == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        if: steps.gate.outputs.should_run == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Check Astral availability
        if: steps.gate.outputs.should_run == 'true'
        shell: bash
        run: |
          python - <<'PY'
          import importlib, sys
          try:
              m = importlib.import_module('astral')
              from astral import Observer
              from astral.moon import moonrise, moonset, phase
              print("Astral version:", getattr(m, '__version__', 'unknown'))
              print("Observer OK:", Observer is not None)
              print("moonrise callable:", callable(moonrise))
          except Exception as e:
              print("❌ Astral import failed:", e)
              sys.exit(1)
          PY

      - name: Clean debug artifacts (optional)
        if: steps.gate.outputs.should_run == 'true'
        run: |
          rm -f Public/_debug-* || true

      # --- Sanity check: sites.yaml ---
      - name: Sanity check — sites.yaml
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import sys, pathlib
          import yaml
          p = pathlib.Path("sites.yaml")
          if not p.exists():
            print("❌ sites.yaml absent"); sys.exit(1)
          data = yaml.safe_load(p.read_text(encoding="utf-8"))
          if not isinstance(data, list) or not data:
            print("❌ sites.yaml doit être une LISTE non vide"); sys.exit(1)
          for i, s in enumerate(data, 1):
            if not isinstance(s, dict) or not all(k in s for k in ("name","lat","lon")):
              print(f"❌ entrée #{i} invalide"); sys.exit(1)
          print(f"✅ sites.yaml OK — {len(data)} site(s)")

      # --- Sanity check: rules.yaml (NOUVEAU) ---
      - name: Sanity check — rules.yaml (flat schema + normalize)
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import sys, json, pathlib, yaml, datetime
          from zoneinfo import ZoneInfo

          p = pathlib.Path("rules.yaml")
          if not p.exists():
              print("❌ rules.yaml absent"); sys.exit(1)

          try:
              raw = yaml.safe_load(p.read_text(encoding="utf-8")) or {}
          except Exception as e:
              print("❌ rules.yaml illisible:", e); sys.exit(1)

          # --- vérifs minimales sur TON schéma plat ---
          required_top = ["overrides","wind","sea","tp_matrix","hysteresis","shelter",
                          "resolution_policy","confidence","corridor","family_hours_local"]
          missing = [k for k in required_top if k not in raw]
          if missing:
              print("❌ rules.yaml: clés manquantes au niveau racine:", missing); sys.exit(1)

          # sous-clés critiques
          crit = []
          for k in ["thunder_wmo","gusts_hard_nogo_kmh","squall_delta_kmh"]:
              if k not in raw["overrides"]: crit.append(f"overrides.{k}")
          for k in ["family_max_kmh","nogo_min_kmh","onshore_degrade_kmh"]:
              if k not in raw["wind"]: crit.append(f"wind.{k}")
          for k in ["family_max_hs_m","nogo_min_hs_m"]:
              if k not in raw["sea"]: crit.append(f"sea.{k}")
          for k in ["transit","anchor_sheltered"]:
              if k not in raw["tp_matrix"]: crit.append(f"tp_matrix.{k}")
          for k in ["start_h","end_h"]:
              if k not in raw["family_hours_local"]: crit.append(f"family_hours_local.{k}")
          if crit:
              print("❌ rules.yaml: sous-clés critiques manquantes:", crit); sys.exit(1)

          # --- normalisation -> structure commune attendue par le reader (et debug) ---
          # 1) heuristiques pour min/max fenêtre (4–6 h), à partir de ton corridor
          def _parse_leg_span(span: str, default_min: float, default_max: float):
              # accepte "1-1.5" ou "1" -> float
              if isinstance(span, (int,float)): return float(span), float(span)
              s = str(span)
              if "-" in s:
                  a,b = s.split("-",1)
                  try: return float(a), float(b)
                  except: return default_min, default_max
              try: 
                  v = float(s); 
                  return v, v
              except:
                  return default_min, default_max

          leg = (raw.get("corridor",{}).get("leg_structure_hours") or {})
          tmin,tmax = _parse_leg_span(leg.get("transit_out","1-1.5"), 1.0, 1.5)
          bmin,bmax = _parse_leg_span(leg.get("transit_back","1-1.5"), 1.0, 1.5)
          amin = float(leg.get("anchor_min", 2))
          amax = float(leg.get("anchor_max", 4))
          win_min = int(round(tmin + amin + bmin))
          win_max = int(round(tmax + amax + bmax))
          # garde-barrières Family (on force 4–6 si valeurs aberrantes)
          win_min = max(4, min(win_min, 6))
          win_max = max(win_min, min(win_max, 6))

          # 2) mapping plat -> “family/thresholds/combined…”
          normalized = {
            "meta": {
              "version": 1,
              "tz_default": "Africa/Tunis",
              "source_schema": "flat"
            },
            "family": {
              "hours_local": {
                "start": int(raw["family_hours_local"]["start_h"]),
                "end": int(raw["family_hours_local"]["end_h"])
              },
              "window_hours": {
                "min": win_min,
                "max": win_max
              },
              "thresholds": {
                "wind": {
                  "family_max_kmh": float(raw["wind"]["family_max_kmh"]),
                  "no_go_min_kmh":  float(raw["wind"]["nogo_min_kmh"]),
                  "onshore_downgrade_kmh": float(raw["wind"]["onshore_degrade_kmh"]),
                },
                "gusts": {
                  "no_go_min_kmh":  float(raw["overrides"]["gusts_hard_nogo_kmh"]),
                  "squall_delta_kmh": float(raw["overrides"]["squall_delta_kmh"]),
                },
                "waves": {
                  "hs_family_max_m": float(raw["sea"]["family_max_hs_m"]),
                  "hs_no_go_min_m": float(raw["sea"]["nogo_min_hs_m"]),
                  # transit strict depuis tp_matrix.transit
                  "tp_min_at_hs_lt_0_4_s": float(raw["tp_matrix"]["transit"]["hs_lt_0_4_family_tp_s"]),
                  "tp_min_at_hs_0_4_0_5_s": float(raw["tp_matrix"]["transit"]["hs_0_4_0_5_family_tp_s"]),
                },
                "visibility_km_min": float(raw.get("overrides",{}).get("visibility_km_min", 5.0))
              },
              "combined": {
                # défauts FABLE (non présents dans ton YAML) — restent sûrs
                "short_steep": {
                  "downgrade": {"hs_min_m": 0.5, "tp_max_s": 6.0},
                  "hard_nogo": {"hs_min_m": 0.6, "tp_max_s": 5.0}
                },
                "hysteresis": {
                  "hs_m": float(raw["hysteresis"]["hs_m"]),
                  "wind_kmh": float(raw["hysteresis"]["wind_kmh"])
                }
              },
              "shelter_bonus": {
                "enabled": True,
                "radius_km_default": float(raw["shelter"]["radius_km_default"]),
                "apply_on_transit": bool(raw["shelter"].get("apply_on_transit", False)),
                "anchor": {
                  "gusts_allow_up_to_kmh": float(raw["shelter"]["anchor_gusts_allow_up_to_kmh"]),
                  "sustained_allow_up_to_kmh": float(raw["shelter"]["anchor_sustained_allow_up_to_kmh"]),
                  "squall_delta_max_kmh": float(raw["shelter"]["anchor_squall_delta_max_kmh"]),
                  "require_lee": bool(raw["shelter"]["require_lee"]),
                  "max_fetch_km": float(raw["shelter"]["max_fetch_km"])
                }
              },
              "anchor_sheltered": {
                "waves": {
                  "hs_le_0_35_family_tp_s": float(raw["tp_matrix"]["anchor_sheltered"]["hs_le_0_35_family_tp_s"]),
                  "hs_le_0_35_expert_tp_min_s": float(raw["tp_matrix"]["anchor_sheltered"]["hs_le_0_35_expert_tp_min_s"])
                }
              },
              "corridor": {
                "check": True,
                "buffer_km": 5,
                "samples": int(raw["corridor"]["samples"]),
                "validate_departure_and_return": bool(raw["corridor"].get("validate_departure_and_return", True))
              },
              "thunder_codes": list(map(int, raw["overrides"]["thunder_wmo"]))
            },
            "confidence": {
              "high": {
                "wind_spread_kmh": float(raw["confidence"]["high"]["wind_spread_kmh_lt"]),
                "hs_spread_m": float(raw["confidence"]["high"]["hs_spread_m_lt"])
              },
              "medium_wind_spread_kmh": 8.0,  # garde réglage standard
              "cap_high_if_single_wave_source": True,
              "min_wind_models_for_not_low": (
                  2 if bool(raw.get("resolution_policy",{}).get("second_model_required_for_medium", True)) else 1
              )
            }
          }

          # écrire un artefact de debug (et pour les étapes suivantes si utile)
          pub = pathlib.Path("Public"); pub.mkdir(exist_ok=True)
          (pub/"rules.normalized.json").write_text(
            json.dumps(normalized, ensure_ascii=False, indent=2),
            encoding="utf-8"
          )

          # log utile
          print("ℹ️  rules.yaml (flat) chargé et normalisé → Public/rules.normalized.json")
          print("   - Family hours:", normalized["family"]["hours_local"])
          print("   - Window hours:", normalized["family"]["window_hours"])
          print("   - Wind thresholds:", normalized["family"]["thresholds"]["wind"])
          print("   - Waves thresholds:", normalized["family"]["thresholds"]["waves"])
          print("✅ rules.yaml OK")

      - name: Export flags from rules.yaml
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import os, yaml, pathlib
          raw = yaml.safe_load(pathlib.Path("rules.yaml").read_text(encoding="utf-8")) or {}
          http = raw.get("http") or {}

          # Option A: couper totalement l'appel HTTP /v1/astronomy et forcer Astral
          if str(http.get("disable_astronomy_http", "")).strip().lower() in ("1","true","yes","on"):
              with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as fh:
                  fh.write("FABLE_DISABLE_ASTRONOMY_HTTP=1\n")
              print("FABLE_DISABLE_ASTRONOMY_HTTP=1 (from rules.yaml)")

          # (optionnel) centraliser aussi l'ordre des modèles dans rules.yaml:
          # http:
          #   model_order: "icon_seamless,gfs_seamless,ecmwf_ifs04,default"
          mo = (http.get("model_order") or "").strip()
          if mo:
              with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as fh:
                  fh.write(f"FABLE_MODEL_ORDER={mo}\n")
              print(f"FABLE_MODEL_ORDER={mo} (from rules.yaml)")

      # --- Collecte JSON ---
      - name: Generate JSON (window, tz, targeting)
        if: steps.gate.outputs.should_run == 'true'
        env:
          FABLE_TZ: ${{ github.event_name == 'workflow_dispatch' && inputs.tz || steps.gate.outputs.tz_effective }}
          FABLE_WINDOW_HOURS: ${{ github.event_name == 'workflow_dispatch' && inputs.window_hours || '48' }}
          FABLE_START_ISO: ${{ github.event_name == 'workflow_dispatch' && inputs.start_iso || '' }}
          FABLE_ONLY_SITES: ${{ github.event_name == 'workflow_dispatch' && inputs.only_sites || '' }}
          FABLE_ASTRAL_FALLBACK: '1'
          LOG_LEVEL: 'WARNING'
          FABLE_DEBUG_DUMP: '0'
          FABLE_INCLUDE_EXTRAS: '0'
          FABLE_HTTP_RETRIES: '3'
          FABLE_HTTP_TIMEOUT_S: '12'
          FABLE_RULES_PATH: rules.yaml         # ← ajouté
          FABLE_PARALLEL_MODELS: 'icon_seamless,gfs_seamless,ecmwf_ifs04'
          FABLE_PARALLEL_TIMEOUT_S: '12'
          FABLE_PARALLEL_RETRIES: '0'
        run: |
          set -e
          echo "Using FABLE_TZ=$FABLE_TZ"
          echo "Using FABLE_WINDOW_HOURS=$FABLE_WINDOW_HOURS"
          [ -n "$FABLE_START_ISO" ] && echo "Using FABLE_START_ISO=$FABLE_START_ISO"
          [ -n "$FABLE_ONLY_SITES" ] && echo "Using FABLE_ONLY_SITES=$FABLE_ONLY_SITES"
          python main.py || (echo "Collector failed once, retrying in 6s..." && sleep 6 && python main.py)

      # --- Construire un INVENTAIRE séparé (NE PAS écraser index.json de main.py) ---
      - name: Build catalog.json (listing fichiers)
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        env:
          TZ_EFFECTIVE: ${{ steps.gate.outputs.tz_effective }}
        run: |
          import os, json, pathlib, datetime
          from zoneinfo import ZoneInfo
          tz = ZoneInfo(os.environ.get("TZ_EFFECTIVE","Africa/Tunis"))
          pub = pathlib.Path("Public"); pub.mkdir(exist_ok=True)
          files = []
          for p in sorted(pub.glob("*.json")):
              if p.name in ("catalog.json",):
                  continue
              st = p.stat()
              mtime = datetime.datetime.fromtimestamp(st.st_mtime, tz).isoformat()
              files.append({"path": p.name, "size": st.st_size, "modified": mtime})
          (pub/"catalog.json").write_text(json.dumps({
              "generated_at": datetime.datetime.now(tz).isoformat(),
              "files": files
          }, ensure_ascii=False, indent=2), encoding="utf-8")
          print(f"Built catalog.json with {len(files)} item(s) in {tz.key})")

      # --- Sanity check — catalog & files ---
      - name: Sanity check — catalog & files
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        env:
          READER_HOME: ${{ (github.event_name == 'workflow_dispatch' && inputs.reader_home) || 'gammarth-port.json' }}
        run: |
          import json, os, sys, pathlib
          pub = pathlib.Path('Public')
          cat = pub / 'catalog.json'
          if not cat.exists():
              print('❌ Public/catalog.json manquant'); sys.exit(1)
          data = json.loads(cat.read_text(encoding='utf-8'))
          files = data.get('files', [])
          if not files:
              print('❌ catalog.json ne référence aucun fichier'); sys.exit(1)
          missing = []
          for f in files:
              p = pub / f.get('path','')
              if not p.exists() or p.stat().st_size == 0:
                  missing.append(str(p))
          if missing:
              print('❌ Fichiers référencés manquants/vides:', missing); sys.exit(1)
          home = pub / os.environ.get('READER_HOME','gammarth-port.json')
          if not home.exists():
              print('❌ reader_home introuvable:', home); sys.exit(1)
          print('✅ Sanity OK (catalog.json + fichiers)')

      # --- Fraîcheur des JSON ---
      - name: Sanity check — fraîcheur des JSON
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import json, pathlib, sys, datetime
          pub = pathlib.Path('Public')
          files = [pub/f['path'] for f in json.loads((pub/'catalog.json').read_text(encoding='utf-8')).get('files',[])]
          if not files:
              print('❌ Aucun spot détecté'); sys.exit(1)
          mtimes = [(f.name, datetime.datetime.fromtimestamp(f.stat().st_mtime)) for f in files]
          mtimes.sort(key=lambda x: x[1])
          oldest, newest = mtimes[0][1], mtimes[-1][1]
          skew = (newest - oldest).total_seconds()/60.0
          print('⏱️  Écart mtime min/max = %.1f min' % skew)
          if skew > 10:
              print('❌ Trop de décalage entre les JSON de spots (>10 min).',
                    mtimes[0][0], oldest.isoformat(), 'vs', mtimes[-1][0], newest.isoformat())
              sys.exit(1)

      # --- (debug) aperçu d’un JSON ---
      - name: Show one site JSON (debug)
        if: steps.gate.outputs.should_run == 'true'
        run: |
          echo "==== Public listing ===="
          ls -lah Public || true
          echo "==== head of ${{ (github.event_name == 'workflow_dispatch' && inputs.reader_home) || 'gammarth-port.json' }} ===="
          head -c 1500 "Public/${{ (github.event_name == 'workflow_dispatch' && inputs.reader_home) || 'gammarth-port.json' }}" || true
          echo

      # --- Reader FABLE -> Public/windows.json ---
      - name: Run FABLE reader (detect Family GO)
        if: steps.gate.outputs.should_run == 'true'
        env:
          FABLE_RULES_PATH: rules.yaml         # ← ajouté
        run: |
          set -e
          python reader.py \
            --from-dir Public \
            --out Public \
            --home "${{ (github.event_name == 'workflow_dispatch' && inputs.reader_home) || 'gammarth-port.json' }}"

      # --- Vérifier windows.json ---
      - name: Sanity check — windows.json
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import json, pathlib, sys
          p = pathlib.Path('Public/windows.json')
          if not p.exists():
              print('❌ Public/windows.json manquant'); sys.exit(1)
          d = json.loads(p.read_text(encoding='utf-8'))
          if 'windows' not in d:
              print('❌ windows.json ne contient pas la clé "windows"'); sys.exit(1)
          print('✅ windows.json OK —', len(d.get('windows', [])), 'destination(s)')

      # --- Générer windows.md lisible ---
      - name: Create windows.md from windows.json
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        env:
          TZ_EFFECTIVE: ${{ steps.gate.outputs.tz_effective }}
        run: |
          import os, json, pathlib, datetime
          from zoneinfo import ZoneInfo
          pub = pathlib.Path('Public')
          d = json.loads((pub/'windows.json').read_text(encoding='utf-8'))
          tz = ZoneInfo(os.environ.get('TZ_EFFECTIVE','Africa/Tunis'))
          ts = datetime.datetime.now(tz).strftime('%Y-%m-%d %H:%M %Z')
          lines = ['# FABLE — Fenêtres Family GO','',f'Horodatage: {ts} ({tz.key})','']
          wins = d.get('windows', [])
          if not wins:
            lines.append('- Aucune fenêtre Family GO détectée dans l’horizon analysé.')
          else:
            for w in wins:
              lines.append(f"## {w.get('dest_name','?')} ({w.get('dest_slug','?')})")
              for seg in w.get('windows', []):
                lines.append(f"- {seg['start']} → {seg['end']} ({seg['hours']} h)")
              lines.append('')
          (pub/'windows.md').write_text('\n'.join(lines)+'\n', encoding='utf-8')
          print('✅ Public/windows.md généré')

      
      # --- .nojekyll pour GitHub Pages ---
      - name: Add .nojekyll (keep static index.html)
        if: steps.gate.outputs.should_run == 'true'
        shell: bash
        run: |
          set -e
          mkdir -p Public
          : > Public/.nojekyll
          
      # --- Fallback : copier static/index.html si Public/index.html manque ---
      - name: Fallback static index.html (if missing)
        if: steps.gate.outputs.should_run == 'true'
        shell: bash
        run: |
          set -e
          if [ -s Public/index.html ]; then
            echo "Public/index.html présent — je le conserve."
          elif [ -s static/index.html ]; then
            cp -f static/index.html Public/index.html
            echo "Copié static/index.html -> Public/index.html"
          else
            echo "⚠️ static/index.html introuvable — création d'un placeholder minimal."
            printf '<!doctype html><meta charset="utf-8"><title>fable-collector</title><p>Dashboard placeholder</p>' > Public/index.html
          fi
          
      # --- Copier d'autres assets statiques sans écraser les JSON ---

      - name: Copy static assets (optional)
        if: ${{ steps.gate.outputs.should_run == 'true' && hashFiles('static/**') != '' }}
        shell: bash
        run: |
          set -e
          echo "Copying static assets from static/ to Public/…"
          shopt -s nullglob
          mkdir -p Public
          files=(static/*)
          for f in "${files[@]}"; do
            base="$(basename "$f")"
            [[ "$base" == "index.html" ]] && continue   # ne pas écraser Public/index.html
            cp -v "$f" Public/
          done

      # --- Résumé ---
      - name: Job summary (windows)
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        run: |
          import os, json, pathlib
          p = pathlib.Path('Public/windows.json')
          if not p.exists():
              raise SystemExit(0)
          d = json.loads(p.read_text(encoding='utf-8'))
          wins = d.get('windows', [])
          out = ["## FABLE — fenêtres Family GO", ""]
          if not wins:
              out.append("- Aucune fenêtre Family GO détectée.")
          else:
              for w in wins:
                  out.append(f"- **{w.get('dest_name','?')}** ({w.get('dest_slug','?')}):")
                  for seg in w.get('windows', []):
                      out.append(f"  - {seg['start']} → {seg['end']} ({seg['hours']} h)")
          with open(os.environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as fh:
              fh.write("\n".join(out) + "\n")

      # --- Vérification finale ---
      - name: Final outputs check
        if: steps.gate.outputs.should_run == 'true'
        run: |
          set -e
          test -s Public/index.json   || (echo 'index.json manquant ou vide' && exit 1)
          test -s Public/catalog.json || (echo 'catalog.json manquant ou vide' && exit 1)
          test -s Public/windows.json || (echo 'windows.json manquant ou vide' && exit 1)
          test -s Public/windows.md   || (echo 'windows.md manquant ou vide' && exit 1)
          test -s Public/index.html   || (echo 'index.html manquant ou vide' && exit 1)
          echo '✅ Sorties prêtes à publier.'

      - name: List Public artifacts
        if: steps.gate.outputs.should_run == 'true'
        run: |
          echo "==== Public ===="
          ls -lah Public || true
          echo "==============="

      # --- Publication Pages ---
      - name: Setup Pages
        if: steps.gate.outputs.should_run == 'true'
        uses: actions/configure-pages@v5

      - name: Build status.json + status.html (inline healthcheck)
        if: steps.gate.outputs.should_run == 'true'
        shell: python
        env:
          TZ_EFFECTIVE: ${{ steps.gate.outputs.tz_effective }}
        run: |
          import json, pathlib, datetime
          from zoneinfo import ZoneInfo
          tz = ZoneInfo("${{ steps.gate.outputs.tz_effective }}")
          pub = pathlib.Path("Public"); pub.mkdir(exist_ok=True)
          cat = json.loads((pub/"catalog.json").read_text(encoding="utf-8"))
          files = cat.get("files", [])
          # Fraîcheur: on considère "frais" si tous les JSON ont < 3h
          now = datetime.datetime.now(tz)
          stale = []
          for f in files:
              p = pub / f["path"]
              # ignore catalog.json lui-même
              if p.name in ("catalog.json",): 
                  continue
              m = datetime.datetime.fromisoformat(f["modified"])
              age_h = (now - m).total_seconds()/3600.0
              if age_h > 3:
                  stale.append({"path": p.name, "age_h": round(age_h,2)})
          status = {
              "generated_at": now.isoformat(),
              "all_fresh": len(stale)==0,
              "stale": stale,
              "files": files,
          }
          (pub/"status.json").write_text(json.dumps(status, ensure_ascii=False, indent=2), encoding="utf-8")
          (pub/"status.html").write_text(
              "<!doctype html><meta charset='utf-8'><title>status</title>"
              f"<p>Généré: {now.strftime('%Y-%m-%d %H:%M %Z')}</p>"
              + ("<p>OK</p>" if not stale else f"<p>Stale: {len(stale)}</p>"),
              encoding="utf-8"
          )
          print("✅ status.json/html générés")


      - name: Upload artifact
        if: steps.gate.outputs.should_run == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./Public

  deploy:
    needs: build
    if: needs.build.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
